{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qEIWu6OdL2o1",
        "MSSfKkUWMFW8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "F7eu0BbSLckF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czaybPE_x_ih",
        "outputId": "821bc164-0dbb-4a71-a1e8-c1588fc76caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n",
            "Collecting keras-self-attention\n",
            "  Using cached keras_self_attention-0.51.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.23.5)\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm_notebook\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(['stopwords','punkt','wordnet','omw-1.4'])\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "%pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "%pip install keras-self-attention\n",
        "from keras_self_attention import SeqSelfAttention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "qEIWu6OdL2o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()\n",
        "#exploratory data analysis\n",
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YidLK5Il-NSI",
        "outputId": "4bc92386-2a89-4148-c326-a4508add140e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20800 entries, 0 to 20799\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      20800 non-null  int64 \n",
            " 1   title   20242 non-null  object\n",
            " 2   author  18843 non-null  object\n",
            " 3   text    20761 non-null  object\n",
            " 4   label   20800 non-null  int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 812.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing and Tokenization\n"
      ],
      "metadata": {
        "id": "MSSfKkUWMFW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_text(input_text, stopwords_removal=True):\n",
        "#     result = \"\"\n",
        "#     input_text = str(input_text).replace(r'http[\\w:/\\.]+', '')  # eliminate urls\n",
        "#     input_text = str(input_text).replace(r'[^\\.\\w\\s]', '')  # remove all but characters and punctuation\n",
        "#     input_text = str(input_text).replace(r'\\.\\.+', '.')  # substitute multiple periods with a single one\n",
        "#     input_text = str(input_text).replace(r'\\.', ' . ')  # replace periods with a single one\n",
        "#     input_text = str(input_text).replace(r'\\s\\s+', ' ')  # replace multiple spaces with a single one\n",
        "#     input_text = str(input_text).replace(\"\\n\", \"\")  # remove line breaks\n",
        "#     input_text = re.sub(r'[^\\w\\s]', '', input_text).lower()  # convert text to lowercase\n",
        "\n",
        "#     if stopwords_removal:\n",
        "#         input_text = input_text.split(\" \")\n",
        "#         for word in input_text:\n",
        "#             if word not in stopwords.words(\"english\"):\n",
        "#                 result = result + \" \" + word\n",
        "#     else:\n",
        "#         result = input_text\n",
        "\n",
        "#     return ' '.join(result).strip()[1:-3].replace(\" \", \" \")\n",
        "\n",
        "# texts = []\n",
        "# x = df['text']\n",
        "# for line in tqdm_notebook(x, total=df.shape[0]):\n",
        "#  texts.append(preprocess_text(line))"
      ],
      "metadata": {
        "id": "WgO07Ixex7Li"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing\n",
        "x_train,x_test,y_train,y_test = train_test_split(df['text'],df['label'],\n",
        "                                                 test_size=0.2,random_state=42)\n",
        "\n",
        "#tokenization\n",
        "max_length = 128\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_size = 1000\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, char_level=False,\n",
        "                      oov_token=oov_tok)\n",
        "x_train = x_train.astype(str)\n",
        "x_test = x_test.astype(str)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "training_sequences = pad_sequences(training_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "testing_sequences = pad_sequences(testing_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "\n",
        "\n",
        "print(\"Shape of training sequence\",training_sequences.shape)\n",
        "print(\"Shape of testing sequence\",testing_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lufh7UMfnH3H",
        "outputId": "a46d52bc-b2bd-44bc-8756-81f4f6ff9aea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training sequence (16640, 128)\n",
            "Shape of testing sequence (4160, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Initialization\n"
      ],
      "metadata": {
        "id": "G0CmyyonMO1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM"
      ],
      "metadata": {
        "id": "6ijkninndGXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "InHQ3HG_deaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model architecture\n",
        "embedding_dimension = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dimension, input_length=max_length))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))  # Set return_sequences=True\n",
        "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC7YfAGGvEH0",
        "outputId": "f999fdb9-dff7-4b1d-dd03-f749d3ad9ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 128, 32)           32000     \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 128, 256)          164864    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " seq_self_attention_2 (SeqS  (None, 128, 256)          16449     \n",
            " elfAttention)                                                   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 256)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213570 (834.26 KB)\n",
            "Trainable params: 213570 (834.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training model\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2)\n",
        "history = model.fit(training_sequences,\n",
        "                    y_train,\n",
        "                    epochs = 4,\n",
        "                    validation_data = (testing_sequences, y_test),\n",
        "                    callbacks = [early_stop],\n",
        "                    verbose = 2)"
      ],
      "metadata": {
        "id": "hcU5OuYg2Pb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74af8f1-77d4-4955-b59c-efcc719cc8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "520/520 - 328s - loss: 0.3572 - accuracy: 0.8424 - val_loss: 0.2785 - val_accuracy: 0.8990 - 328s/epoch - 631ms/step\n",
            "Epoch 2/4\n",
            "520/520 - 310s - loss: 0.2473 - accuracy: 0.8964 - val_loss: 0.1919 - val_accuracy: 0.9286 - 310s/epoch - 595ms/step\n",
            "Epoch 3/4\n",
            "520/520 - 310s - loss: 0.1833 - accuracy: 0.9305 - val_loss: 0.1830 - val_accuracy: 0.9370 - 310s/epoch - 596ms/step\n",
            "Epoch 4/4\n",
            "520/520 - 285s - loss: 0.1579 - accuracy: 0.9409 - val_loss: 0.1781 - val_accuracy: 0.9327 - 285s/epoch - 547ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions with Model\n"
      ],
      "metadata": {
        "id": "ZR_KT6zudLMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "test_news =  [\"One person believed to be dead on a property near the U.S. border in Langley, B.C., after a fire broke out during a large-scale police operation Friday, the RCMP said Saturday. B.C.'s police watchdog, the Independent Investigations Office of B.C. (IIOBC), confirmed to CBC News that it is now investigating the incident, which left two police vehicles heavily damaged by fire. Officers responded to a report of a distraught individual on the 23000-block of 0 Avenue property, Friday after 10 a.m., according to an RCMP press release. But when officers arrived, they heard gunshots and called in the force's integrated emergency response team (IERT), the release stated.\"]\n",
        "\n",
        "test_news_sequences = tokenizer.texts_to_sequences(test_news)\n",
        "test_news_sequences = pad_sequences(test_news_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "print(test_news_sequences.shape)\n",
        "test_news_pred = model.predict(test_news_sequences)\n",
        "print(\"Probability of fake news:\",test_news_pred)\n",
        "\n",
        "test_news =  [\"Alert! The president is dead\"]\n",
        "\n",
        "test_news_sequences = tokenizer.texts_to_sequences(test_news)\n",
        "test_news_sequences = pad_sequences(test_news_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "print(test_news_sequences.shape)\n",
        "test_news_pred = model.predict(test_news_sequences)\n",
        "print(\"Probability of fake news:\",test_news_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24xx8gSM7IhA",
        "outputId": "1e5d0df4-7406-493e-84e2-b0cd57c78571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128)\n",
            "1/1 [==============================] - 1s 860ms/step\n",
            "Probability of fake news: [[0.02236203]]\n",
            "(1, 128)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Probability of fake news: [[0.9973208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN-LSTM\n"
      ],
      "metadata": {
        "id": "erDmmAoOApRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "tWLfEJ5gAucC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model architecture\n",
        "embedding_dimension = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dimension, input_length=max_length))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#training model\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2)\n",
        "history = model.fit(training_sequences,\n",
        "                    y_train,\n",
        "                    epochs = 4,\n",
        "                    validation_data = (testing_sequences, y_test),\n",
        "                    callbacks = [early_stop],\n",
        "                    verbose = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UAKH-kFAzU6",
        "outputId": "95d8a6d2-3cff-43db-9f82-3ec962ea3287"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 128, 32)           32000     \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 128, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 64, 32)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               82432     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117665 (459.63 KB)\n",
            "Trainable params: 117665 (459.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "520/520 - 56s - loss: 0.3255 - accuracy: 0.8541 - val_loss: 0.1907 - val_accuracy: 0.9279 - 56s/epoch - 108ms/step\n",
            "Epoch 2/4\n",
            "520/520 - 56s - loss: 0.1793 - accuracy: 0.9401 - val_loss: 0.1870 - val_accuracy: 0.9296 - 56s/epoch - 109ms/step\n",
            "Epoch 3/4\n",
            "520/520 - 51s - loss: 0.1494 - accuracy: 0.9504 - val_loss: 0.1813 - val_accuracy: 0.9356 - 51s/epoch - 99ms/step\n",
            "Epoch 4/4\n",
            "520/520 - 53s - loss: 0.1250 - accuracy: 0.9593 - val_loss: 0.1776 - val_accuracy: 0.9389 - 53s/epoch - 102ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model(learning_rate=0.01):\n",
        "  # model = Sequential()\n",
        "  # model.add(Embedding(vocab_size, embedding_dimension, input_length=max_length))\n",
        "  # model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling1D(pool_size=2))\n",
        "  # model.add(LSTM(128, return_sequences=False))\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  # model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
        "  # return model\n",
        "\n",
        "# # Create a classifier with best parameters\n",
        "# model = KerasClassifier(build_fn=create_model, learning_rate=0.01, verbose=0)\n",
        "\n",
        "# # Define the grid search parameters\n",
        "# learning_rate = [0.001, 0.01, 0.1]\n",
        "# param_dist = dict(learning_rate=learning_rate)\n",
        "\n",
        "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_jobs=-1, cv=3)\n",
        "# random_search_result = random_search.fit(training_sequences, y_train, epochs=4, validation_data=(testing_sequences, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=2)], verbose=2)\n",
        "\n",
        "# # Summarize results\n",
        "# print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n"
      ],
      "metadata": {
        "id": "9-KZvjprdATB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions with Model\n"
      ],
      "metadata": {
        "id": "njZ9ObHhMa1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "test_news =  [\"One person believed to be dead on a property near the U.S. border in Langley, B.C., after a fire broke out during a large-scale police operation Friday, the RCMP said Saturday. B.C.'s police watchdog, the Independent Investigations Office of B.C. (IIOBC), confirmed to CBC News that it is now investigating the incident, which left two police vehicles heavily damaged by fire. Officers responded to a report of a distraught individual on the 23000-block of 0 Avenue property, Friday after 10 a.m., according to an RCMP press release. But when officers arrived, they heard gunshots and called in the force's integrated emergency response team (IERT), the release stated.\"]\n",
        "\n",
        "test_news_sequences = tokenizer.texts_to_sequences(test_news)\n",
        "test_news_sequences = pad_sequences(test_news_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "print(test_news_sequences.shape)\n",
        "test_news_pred = model.predict(test_news_sequences)\n",
        "print(\"Probability of fake news:\",test_news_pred)\n",
        "\n",
        "test_news =  [\"Alert! The president is dead\"]\n",
        "\n",
        "test_news_sequences = tokenizer.texts_to_sequences(test_news)\n",
        "test_news_sequences = pad_sequences(test_news_sequences, maxlen = max_length,\n",
        "                                   padding = padding_type,\n",
        "                                   truncating = trunc_type)\n",
        "print(test_news_sequences.shape)\n",
        "test_news_pred = model.predict(test_news_sequences)\n",
        "print(\"Probability of fake news:\",test_news_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdtpRDwhdPvf",
        "outputId": "ed562d6c-c36f-42fc-f0af-1173163d3df5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128)\n",
            "1/1 [==============================] - 1s 791ms/step\n",
            "Probability of fake news: [[0.02587314]]\n",
            "(1, 128)\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Probability of fake news: [[0.99830014]]\n"
          ]
        }
      ]
    }
  ]
}